---
title: 理论
permalink: /中间件/kafka/理论/ru
---

## 消费端自动提交

`kafka`消费端在配置消息提交时，可以选择手动提交和自动提交，如果选择自动提交，将涉及到2个参数：

* `enable.auto.commit`:`true`，标识开启自动提交
* `auto.commit.interval.ms`: 自动提交`offset`的时间间隔毫秒数

当设置 `enable.auto.commit` 为 true，**Kafka 会保证在开始调用 poll 方法时，并且距离上次提交offset的时间间隔大于`auto.commit.interval.ms`， 会提交上次 poll 返回的所有消息**。从顺序上来说，poll 方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。



## 如何保证数据不丢失

首先，`kafka`在生产端、服务端和客户端都存在消息丢失的情况：

* 生产端：由于网络原因，消息发送超时，造成数据丢失；可以通过异步处理，接受到超时异常，持久化消息然后稍后重试的方式解决；
* 服务端：消息发送完后，生产端如果不需要接受服务端生产的`ack(即ack=0)`，将不确定消息是否以及持久化了；可能消息没落盘就宕机了；通常最少需要设置`ack=1`（也可能存在消息丢失，但是概率小了很多，比如主分区落盘后刚好挂了，其他副本尚未同步到该偏移，导致数据丢失）；
* 消费端：当消息是先提交，后消费时，如果消费过程中消费端服务宕机了，将造成数据丢失；可以通过手动提交；
  * 手动同步提交：存在阻塞问题
  * 手动异步提交：如果提交失败，将不会重试，造成消息重复消费；
  * 手动同步+异步组合提交： 异步提交，如果提交失败捕获异常，并进行同步提交；



> 如何保证数据不重复消费
>
> 这个是消费端的问题，主要做幂等判断，先判断数据是否未被消费过，然后进行消费，否则直接不处理；





## kafka 存储机制

1. 一个topic对应多个partition (每个主题对应物理文件夹为 topic-0, topic-1, ...)
2. 一个partition对应多个segment
3. 一个segment对应4个文件（xxx.index, xxx.log, xxx.timeindex, xxx.snapshot）

index 文件

采用稀疏矩阵进行存储， 结构大概类似如下

|topic offset|position|
|---|---|
|330|1225|
|380|1456|
|420|1928|

第一行存储kafka 的消息偏移， 第二行存储 物理消息相对文件头偏移。

log 文件

|message|offset|position|
|---|---|---|
|1|330|1225|
|2|380|1456|
|3|420|1928|

> 参考文档
>
> https://mp.weixin.qq.com/s?__biz=Mzg3MTcxMDgxNA==&mid=2247488841&idx=1&sn=2ea884012493403ab45b450271708fc8&source=41#wechat_redirect
>

## kafka实现延迟队列（供参考）

生产者发送消息到broker中，并附上需要延迟执行的时间， 消费者从broker中拉取消息，获取消息发送时间， 加上延迟执行时间，然后把消息放到延迟队列中执行。

> delayQueue 相关源码
>
> https://www.cnblogs.com/dwlsxj/p/delayedQueue.html


## 日志清除策略

在 kafka 中， 存在2种日志， 数据日志和操作日志。

数据日志： kafka的topic中存储的数据；配置项为 server.properties下的 log.dirs, 默认使用 配置项 log.dir

操作日志：kafka中记录操作的日志


### 数据日志清理



**日志删除**

按照指定的策略**直接删除**不符合条件的日志。



1. 按时间删除

```shell
log.retention.ms
log.retention.minutes
log.retention.hours=168  #默认会保留7天
```

2. 按size删除

```shell
log.retention.bytes=-1 # 无限制
```

Kafka的日志删除策略并不是非常严格的（比如如果log.retention.bytes设置了10G的话，并不是超过10G的部分就会立刻删除，只是被标记为待删除，Kafka会在恰当的时候再真正删除）；



**日志压缩**

按照消息的key进行整合，有相同key的但有不同value值，只保留最后一个版本。



### 操作日志删除

Kafka的日志删除策略并不是非常严格的（比如如果log.retention.bytes设置了10G的话，并不是超过10G的部分就会立刻删除，只是被标记为待删除，Kafka会在恰当的时候再真正删除。

